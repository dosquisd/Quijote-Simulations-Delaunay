{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5VHHmXN_QNe"
   },
   "source": [
    "## Ejecutar\n",
    "\n",
    "Estas celdas son las responsables de guardar la información en JSON de las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1738807661634,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "3WuS6V5SwqhZ"
   },
   "outputs": [],
   "source": [
    "# TODO: Buscar la dimensión fractal con el método de box counting\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import igraph as ig\n",
    "import networkx as nx\n",
    "\n",
    "import nolds\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "root: str = \"./quijote\"\n",
    "graphs_root: str = f\"{root}/grafos\"\n",
    "\n",
    "assert os.path.exists(graphs_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4uQEgXTn6UR"
   },
   "source": [
    "Pienso que la mejor manera de guardar todas las métricas puede ser por medio de un JSON (básicamente un diccionario, o un par clave valor), y pienso que quizás sea la mejor manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1738800653048,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "SHYzRBi5oJwT"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(g: ig.Graph, save_dict: dict,\n",
    "                      laplacian_path: str, cutoff: int | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Aquí se calculan literalmente todas las métricas que se necesitan para el grafo `g`,\n",
    "    y son guardadas en un diccionario (en `save_dict`) todos los valores correspondientes\n",
    "    de cada métrica.\n",
    "\n",
    "    Args:\n",
    "        g (igraph.Graph): Grafo no dirigido el cual se le sacarán las métricas, es importante anotar\n",
    "            que las aristas deben tener un peso el cual es llamado `distance`.\n",
    "        save_dict (dict): Diccionario en el cual se guardarán el resultado de las métricas.\n",
    "        laplacian_path (str): Nombre del archivo (junto a su ubicación) donde se guardará el\n",
    "            resultado de la matriz laplaciana. La extensión de este tipo de archivo debe ser .npz.\n",
    "        cutoff (int | None): Este parametro es esencial para especificar qué tan aproximado se\n",
    "            quiere que las métricas de centralidad de betweenness y closeness sean. Por defecto,\n",
    "            `cutoff=None`, lo que significa que no se hace ninguna aproximación, es decir, que se\n",
    "            retorna el valor real.\n",
    "    Returns:\n",
    "        None: La función no retorna nada, únicamente devuelve el diccionario completo con las\n",
    "            métricas que se calcularon y con la matriz laplaciana guardada en la dirección que se\n",
    "            especificó previamente.\n",
    "    \"\"\"\n",
    "\n",
    "    def global_efficiency(g: ig.Graph) -> float:\n",
    "        shortest_paths = g.distances()\n",
    "        efficiency = 0.0\n",
    "        n = len(g.vs)\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if shortest_paths[i][j] > 0:\n",
    "                    efficiency += 1/shortest_paths[i][j]\n",
    "\n",
    "        efficiency /= (n * (n - 1) / 2)\n",
    "\n",
    "        return efficiency\n",
    "\n",
    "    def local_efficiency(g: ig.Graph, v: ig.Vertex) -> float:\n",
    "        neighbors = g.neighbors(v)\n",
    "        subgraph = g.subgraph(neighbors)\n",
    "\n",
    "        if len(neighbors) <= 1:\n",
    "            return 0\n",
    "\n",
    "        return global_efficiency(subgraph)\n",
    "\n",
    "    # Métricas de eficiencia\n",
    "    if 'global_efficiency' not in save_dict:\n",
    "        print(\"Calcular 'global_efficiency'\")\n",
    "        try:\n",
    "            efficiency = global_efficiency(g)\n",
    "            save_dict['global_efficiency'] = efficiency\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "\n",
    "    if 'local_efficiencies' not in save_dict:\n",
    "        print(\"Calcular 'local_efficiencies'\")\n",
    "        try:\n",
    "            local_efficiencies = [local_efficiency(g, v.index) for v in g.vs]\n",
    "            avg_local_efficiency = sum(local_efficiencies) / len(local_efficiencies)\n",
    "\n",
    "            save_dict['local_efficiencies'] = local_efficiencies\n",
    "            save_dict['avg_local_efficiency'] = avg_local_efficiency\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "\n",
    "    # Calcula la centralidad de grado y normalízala\n",
    "    degree = g.degree()\n",
    "    degree_distribution = np.array(degree) / sum(degree)\n",
    "\n",
    "    # Entropia\n",
    "    if 'entropy' not in save_dict:\n",
    "        print(\"Calcular 'entropy\")\n",
    "        graph_entropy = entropy(degree_distribution)\n",
    "        save_dict['entropy'] = graph_entropy\n",
    "\n",
    "    # Dimensión fractal (box counting)\n",
    "    if 'fractal_dimension' not in save_dict:\n",
    "        print(\"Calcular 'fractal_dimension'\")\n",
    "        # Falta buscar la función todavía, pero se aplicaría\n",
    "        # sobre `degree_distribution`\n",
    "        pass\n",
    "\n",
    "    # Hurst\n",
    "    if 'hurst' not in save_dict:\n",
    "        print(\"Calcular 'hurst'\")\n",
    "        hurst = nolds.hurst_rs(degree_distribution, fit='poly')\n",
    "        save_dict['hurst'] = hurst\n",
    "\n",
    "    # Centralidad\n",
    "    if 'closeness' not in save_dict:\n",
    "        print(\"Calcular 'closeness'\")\n",
    "        closeness = g.closeness(weights='distance', normalized=True, cutoff=cutoff)\n",
    "        save_dict['closeness'] = closeness\n",
    "\n",
    "    if 'betweenness' not in save_dict:\n",
    "        print(\"Calcular 'betweenness'\")\n",
    "        betweenness = g.betweenness(directed=False, weights='distance', cutoff=cutoff)\n",
    "        save_dict['betweenness'] = betweenness\n",
    "\n",
    "    if 'eigenvector' not in save_dict:\n",
    "        print(\"Calcular 'eigenvector'\")\n",
    "        eigenvector = g.eigenvector_centrality(directed=False, weights='distance', scale=False)\n",
    "        save_dict['eigenvector'] = eigenvector\n",
    "\n",
    "    if 'convergence' not in save_dict:\n",
    "        print(\"Calcular 'convergence'\")\n",
    "        convergence = g.convergence_degree()\n",
    "        save_dict['convergence'] = convergence\n",
    "\n",
    "    # Matriz laplaciana (La matriz laplaciana no se demora ada)\n",
    "    G = g.to_networkx()\n",
    "    laplacian = nx.laplacian_matrix(G, weight='distance')\n",
    "\n",
    "    # Guardar matriz si es un archivo .npz\n",
    "    if os.path.splitext(laplacian_path)[1] == '.npz':\n",
    "        sp.save_npz(laplacian_path, laplacian)\n",
    "        save_dict['laplacian'] = laplacian_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 929775,
     "status": "ok",
     "timestamp": 1738803769019,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "d_c6dy-L0KIr",
    "outputId": "d07c8687-d475-4b3e-a5f4-47a213ba997e"
   },
   "outputs": [],
   "source": [
    "save = True\n",
    "cont = 1\n",
    "snapnum = \"001\"  # @param\n",
    "\n",
    "# Estas iteraciones son únicamente válidas cuando el snapnum va de 0 hasta 4\n",
    "if os.path.exists(f'{graphs_root}/metrics.json'):\n",
    "    with open(f'{graphs_root}/metrics.json', 'r') as json_data:\n",
    "        metrics = json.load(json_data)\n",
    "else:\n",
    "    metrics = {}\n",
    "\n",
    "try:\n",
    "    # Iterar sobre cada simulación con grafos creados\n",
    "    for simu in os.listdir(graphs_root):\n",
    "        tmp_path = f'{graphs_root}/{simu}'\n",
    "        if not os.path.isdir(tmp_path):\n",
    "            continue\n",
    "\n",
    "        if simu not in metrics:\n",
    "            metrics[simu] = {}\n",
    "\n",
    "        # Se podria crear una función para evitar duplicar código\n",
    "        if simu == \"randoms\":\n",
    "            # Si no hay un grafo para el snapnum asignado, saltarlo\n",
    "            graph_path = f'{snapdir}/{simu}_{snapnum}.graphml'\n",
    "            if not os.path.exists(graph_path):\n",
    "                continue\n",
    "\n",
    "            if snapnum not in metrics[simu][i]:\n",
    "                metrics[simu][i][snapnum] = {}\n",
    "\n",
    "            # Calcular las métricas del grafo\n",
    "            laplacian_path = f'{snapdir}/laplacian_{simu}_{snapnum}.npz'\n",
    "            g = ig.Graph.Read_GraphML(graph_path)\n",
    "            print(f'{cont}. {graph_path} -- Vertices {len(g.vs):,} -- Aristas {len(g.es):,}')\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            calculate_metrics(g, metrics[simu][i][snapnum], laplacian_path)\n",
    "            tf = time.perf_counter() - t0\n",
    "\n",
    "            print(f'Tiempo: {tf} segundos\\n')\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "        # Iterar sobre las realizaciones\n",
    "        for i in os.listdir(tmp_path):\n",
    "            snapdir = f'{tmp_path}/{i}'\n",
    "            if i not in metrics[simu]:\n",
    "                metrics[simu][i] = {}\n",
    "\n",
    "            # Si no hay un grafo para el snapnum asignado, saltarlo\n",
    "            graph_path = f'{snapdir}/{simu}_{snapnum}.graphml'\n",
    "            if not os.path.exists(graph_path):\n",
    "                continue\n",
    "\n",
    "            if snapnum not in metrics[simu][i]:\n",
    "                metrics[simu][i][snapnum] = {}\n",
    "\n",
    "            # Calcular las métricas del grafo\n",
    "            laplacian_path = f'{snapdir}/laplacian_{simu}_{snapnum}.npz'\n",
    "            g = ig.Graph.Read_GraphML(graph_path)\n",
    "            print(f'{cont}. {graph_path} -- Vertices {len(g.vs):,} -- Aristas {len(g.es):,}')\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            calculate_metrics(g, metrics[simu][i][snapnum], laplacian_path)\n",
    "            tf = time.perf_counter() - t0\n",
    "\n",
    "            print(f'Tiempo: {tf} segundos\\n')\n",
    "\n",
    "            cont += 1\n",
    "\n",
    "        print()\n",
    "except KeyboardInterrupt:\n",
    "    save = False\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "if save:\n",
    "    print('Guardando métricas...')\n",
    "    with open(f'{graphs_root}/metrics.json', 'w') as json_data:\n",
    "        json.dump(metrics, json_data, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgoabXoH5XsF"
   },
   "source": [
    "## Prueba cálculo de métricas\n",
    "\n",
    "Las métricas que nos interesan son las siguientes:\n",
    "- De eficiencia: Global Efficiency, Local Efficiency y Average Local Efficiency.\n",
    "- De centralidad: Closeness, Betweenness, Eigenvector y Convergence Degree.\n",
    "- Espectrales: Obtener matriz laplaciana.\n",
    "- Entropia.\n",
    "- Fractalidad: Obtener la dimensión fractal (utilizando el método de box counting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4333,
     "status": "ok",
     "timestamp": 1727367693090,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "Jqvfd7Qf0ydi",
    "outputId": "4335f0cc-d01c-4091-9c58-00b443836388"
   },
   "outputs": [],
   "source": [
    "# Archivo de ejemplo para calcular métricas\n",
    "ex_graph_path = f'{graphs_root}/h_m/100/h_m_001.graphml'\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "g = ig.Graph.Read_GraphML(ex_graph_path)  # Pruebas con igraph\n",
    "print(f'Tiempo leyendo el grafo en igraph: {time.perf_counter() - t0}')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "G = ig.Graph.to_networkx(g)  # Para pruebas con networkx\n",
    "print(f'Tiempo convirtiendo a networkx: {time.perf_counter() - t0}')\n",
    "\n",
    "# No hay una implementación directa de la métrica de eficiencia en iGraph, pero sí en Networkx\n",
    "# entonces me gustaría testear qué tal va en tiempo ambas.\n",
    "# Hasta el momento, el tiempo de iGraph a Networkx no es tampoco tan grave, entonces puede ser viable\n",
    "\n",
    "print(f'No. Nodos: {len(g.vs):,}')\n",
    "print(f'No. Aristas: {len(g.es):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frLVuev81YII"
   },
   "source": [
    "Para no perder el hilo de mis pensamientos, creo que será necesario utilizar varios nucleos del procesador y quizás el uso de memoria virtual con ayuda de dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cZHpzOX5W3j"
   },
   "source": [
    "### Métricas de eficiencia\n",
    "\n",
    "En igraph está [aquí](https://igraph.org/c/doc/igraph-Structural.html#efficiency-measures) las métricas que nos servirían en todo caso. La documentación está en C, pero puede sirve de igual forma\n",
    "\n",
    "En networkx está aquí [aquí](https://networkx.org/documentation/stable/reference/algorithms/efficiency_measures.html). Afortunadamente, aquí sí se puede implementar directamente en python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OG7yZHD--Vyd"
   },
   "source": [
    "#### Global Efficiency of the graph\n",
    "\n",
    "En igraph no hay una implementación directa, así que tocó hacerla de cero. En cambio, en networkx sí la hay ([aquí](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.efficiency_measures.global_efficiency.html#networkx.algorithms.efficiency_measures.global_efficiency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdBZu2bO6Yk5"
   },
   "outputs": [],
   "source": [
    "def global_efficiency(g: ig.Graph) -> float:\n",
    "    shortest_paths = g.distances()\n",
    "    efficiency = 0.0\n",
    "    n = len(g.vs)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if shortest_paths[i][j] > 0:\n",
    "                efficiency += 1/shortest_paths[i][j]\n",
    "\n",
    "    efficiency /= (n * (n - 1) / 2)\n",
    "\n",
    "    return efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 4093888,
     "status": "error",
     "timestamp": 1727371796414,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "q4yFaqQY7fY8",
    "outputId": "3dd8cd98-7279-4a64-88aa-6c440b4ddeb6"
   },
   "outputs": [],
   "source": [
    "#t0 = time.perf_counter()\n",
    "#efficiency = global_efficiency(g)\n",
    "#print(f'Tiempo total: {time.perf_counter() - t0}. Eficiencia: {efficiency}')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "efficiency = nx.global_efficiency(G)\n",
    "print(f'Tiempo total: {time.perf_counter() - t0}. Eficiencia: {efficiency}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKyqtXKC_EqT"
   },
   "source": [
    "Networkx es una puta mierda bien lenta XD. Sin duda el ganador acá es igraph, además de que es excelente confirmar que las métricas sí esté dando igual en ambas. ME ENCANTA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gc0Mf1v_5U8"
   },
   "source": [
    "#### Local Efficiency Around Each Vertex\n",
    "\n",
    "En networkx no encontré una así directa, existe una función parecida, pero no es exactamente la misma, en cualquier caso, es [esta](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.efficiency_measures.efficiency.html#networkx.algorithms.efficiency_measures.efficiency), pero no me convence y no veo tan clara su implementación siendo honesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kGMb7EL_8rf"
   },
   "outputs": [],
   "source": [
    "def local_efficiency(g: ig.Graph, v: ig.Vertex):\n",
    "    neighbors = g.neighbors(v)\n",
    "    subgraph = g.subgraph(neighbors)\n",
    "\n",
    "    if len(neighbors) <= 1:\n",
    "        return 0\n",
    "\n",
    "    return global_efficiency(subgraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1727367427514,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "O6SV5L8fABly",
    "outputId": "8c5016b7-67df-4f29-828b-6ba98dabe370"
   },
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "local_efficiencies = [local_efficiency(g, v.index) for v in g.vs]\n",
    "print(f\"Tiempo: {time.perf_counter() - t0}. Eficiencias locales -- Máx {max(local_efficiencies)} -- Min {min(local_efficiencies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K90IBFS9_RwH"
   },
   "source": [
    "#### Average Local Efficiency\n",
    "\n",
    "En igraph [aquí](https://igraph.org/c/doc/igraph-Structural.html#igraph_average_local_efficiency).  \n",
    "En networkx [aquí](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.efficiency_measures.local_efficiency.html#networkx.algorithms.efficiency_measures.local_efficiency)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJPhgYi197tt"
   },
   "outputs": [],
   "source": [
    "#t0 = time.perf_counter()\n",
    "#avg_local_efficiency = sum(local_efficiencies) / len(local_efficiencies)\n",
    "#print(f\"Tiempo: {time.perf_counter() - t0}. Eficiencias local promedio: {avg_local_efficiency}\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "local_efficiency = nx.local_efficiency(G)\n",
    "print(f\"Tiempo: {time.perf_counter() - t0}. Eficiencia local: {local_efficiency}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMfYqhmwD15S"
   },
   "source": [
    "EXCELENTE!!!!!!! igraph es la absoluta verga en cuanto a velocidad se refiere. Y lo que me pone más contento es que ya confirmamos que a pesar de que estemos creando nuestras propias funciones para calcular nuestras métricas, todo esté saliendo excelente! Estoy muy contento sinceramente, espero que puedas sentir lo mismo que yo viendo este colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRl60u3qGCIT"
   },
   "source": [
    "### Metricas de centralidad\n",
    "\n",
    "Aquí lo bueno que es que afortunadamente, en igraph sí se pueden calcular perfectamente estas métricas sin problemas, al igual que en networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzDv6GQOIftn"
   },
   "source": [
    "#### Closeness\n",
    "\n",
    "igraph. [Aquí](https://python.igraph.org/en/stable/api/igraph.GraphBase.html#closeness).  \n",
    "networkx. [Aquí](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.closeness_centrality.html#networkx.algorithms.centrality.closeness_centrality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8Y1PFV8Dyfh"
   },
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "closeness = g.closeness(weights='distance', normalized=True)\n",
    "print(f'Tiempo {time.perf_counter() - t0}. Closeness -- min {min(closeness)} -- máx {max(closeness)}')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "closeness = nx.closeness_centrality(G, distance='distance', wf_improved=False)\n",
    "print(f'Tiempo {time.perf_counter() - t0}. Closeness -- min {min(closeness.values())} -- máx {max(closeness.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sd0e2A-PWhB"
   },
   "source": [
    "XD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95DelNs4IhcV"
   },
   "source": [
    "#### Betweenness\n",
    "\n",
    "igraph. [Aquí](https://python.igraph.org/en/stable/api/igraph.GraphBase.html#betweenness).  \n",
    "networkx. [Aquí](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html#networkx.algorithms.centrality.betweenness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 88938,
     "status": "error",
     "timestamp": 1727239047489,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "6SsttxfbIisv",
    "outputId": "6203f596-ef6a-40ce-dc20-18ea7bb1926a"
   },
   "outputs": [],
   "source": [
    "# Así el pc no me da pa hacerlo XD. Raramente se me apaga cuando está cuando está con networkx xd\n",
    "# sin embargo, sí dan lo mismo, ya lo confirmé! Antes lo ejecuté y se demoraba ~12 mins\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "betweenness = g.betweenness(directed=False, weights='distance')\n",
    "print(f'Tiempo {time.perf_counter() - t0}. Betweenness -- min {min(betweenness)} -- máx {max(betweenness)}')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "betweenness = nx.betweenness_centrality(G, weight='distance', normalized=False)\n",
    "print(f'Tiempo {time.perf_counter() - t0}. Betweenness -- min {min(betweenness.values())} -- máx {max(betweenness.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPw9gOq_IjTb"
   },
   "source": [
    "#### Eigenvector\n",
    "\n",
    "igraph. [Aquí](https://python.igraph.org/en/stable/api/igraph.GraphBase.html#eigenvector_centrality).  \n",
    "networkx. [Aquí](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.eigenvector_centrality.html#networkx.algorithms.centrality.eigenvector_centrality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3962,
     "status": "ok",
     "timestamp": 1727238958553,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "tj09QLVXIl_J",
    "outputId": "19e25faf-3b09-4674-94e1-e79c5c113b4d"
   },
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "eigenvector = g.eigenvector_centrality(directed=False, weights='distance', scale=False)\n",
    "print(f'Tiempo {time.perf_counter() - t0}. Eigenvector -- min {min(eigenvector)} -- máx {max(eigenvector)}')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "eigenvector = nx.eigenvector_centrality(G, weight='distance')\n",
    "print(f'Tiempo {time.perf_counter() - t0}. Eigenvector -- min {min(eigenvector.values())} -- máx {max(eigenvector.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbXMWtMWeH5H"
   },
   "source": [
    "Qué chévere, bastante rápida ambas. Pero sigue siendo mejor mi igraph querido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41do8mgxImTK"
   },
   "source": [
    "#### Convergence\n",
    "\n",
    "En igraph la función sí se encuentra (ver [aquí](https://python.igraph.org/en/stable/api/igraph.GraphBase.html#convergence_degree)), pero está el grandisimo problema de que no está documentada, por tanto, me tocará conformarme con los parametros que salen mencionados en la implementación en C ([aquí](https://igraph.org/c/doc/igraph-Structural.html#igraph_convergence_degree)). Parametros los cuales tampoco aplicarían mucho en este caso realmente, entonces supongo que se irá sin parametros XD\n",
    "\n",
    "En networkx es peor, porque la gran puta función no está"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1727239920823,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "760aAW0uIpti",
    "outputId": "c40575e8-dcd1-4fc8-d7ab-8fc090f00d5c"
   },
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "convergence = g.convergence_degree()\n",
    "print(f'Tiempo {time.perf_counter() - t0}. convergence -- min {min(convergence)} -- máx {max(convergence)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL87CNCxif2R"
   },
   "source": [
    "### Espectrales\n",
    "\n",
    "igraph. [Aquí](https://python.igraph.org/en/stable/api/igraph.GraphBase.html#laplacian).  \n",
    "networkx. [Aquí](https://networkx.org/documentation/stable/reference/generated/networkx.linalg.laplacianmatrix.laplacian_matrix.html#networkx.linalg.laplacianmatrix.laplacian_matrix).\n",
    "\n",
    "Para tener en cuenta, la matriz laplaciana de networkx está utilizando un objeto de la clase scipy, en concreto, este de [acá](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_array.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25998,
     "status": "ok",
     "timestamp": 1727242091847,
     "user": {
      "displayName": "juan navarro",
      "userId": "04439387566352878296"
     },
     "user_tz": 300
    },
    "id": "4T247j4dignh",
    "outputId": "65215c1d-c159-48c9-e05c-97b106eb3fe1"
   },
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "laplacian_g = g.laplacian(weights='distance', mode='all')\n",
    "tf = time.perf_counter() - t0\n",
    "print(f'Tiempo: {tf}. min: {min(map(min, laplacian_g))} x {max(map(max, laplacian_g))}')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "laplacian_G = nx.laplacian_matrix(G, weight='distance')\n",
    "print(f'Tiempo: {time.perf_counter() - t0}. min: {laplacian_G.min()} -- max: {laplacian_G.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJa9OIV0l6XD"
   },
   "source": [
    "Ve, por primera vez ganó networkx xd. Excelente saberlo en realidad, además de confirmar que den lo mismo.\n",
    "\n",
    "En este caso, va a ser completamente necesario utilizar networkx para calcular esta métrica en particular, puesto que se crashea la sesión si se utiliza igraph por el número de nodos, ya que, esta matriz laplaciana queda con la forma de $N \\times N$, y si utilizamos $400.000$ nodos (lo cual no es exagerado), pasa lo que pasa. Entonces, la conversión a networkx será necesaria aunque cueste su debido tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8_iTGyQmZru"
   },
   "source": [
    "### Entropia & Fractalidad\n",
    "\n",
    "En estas métrica de acá no hay documentación por parte de ambas librerias, pero sí de scipy en el caso de la entropia ([aquí](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html)), pero no me gustaría confirmar con David cómo quiere implementarla exactamente, porque no lo tengo tan claro en realidad. En el código que me envió, calcula la entropia en la distribución de los grados de cada nodo.\n",
    "\n",
    "Y, en el caso de la fractalidad, no lo tengo tampoco tan claro, entonces sería bueno verlo también. Por mientras, trabajaré así sin estas dos métricas hasta que ya se tenga algo más claro. Cualquier cosa lo colocaré acá!!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1cZHpzOX5W3j"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
